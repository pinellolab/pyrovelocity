---
title: "Inference with PyroVelocity"
format:
  html:
    code-fold: false
---

# Inference with PyroVelocity

This guide explains how to perform inference with PyroVelocity, covering both the legacy and modular implementations.

## Legacy Implementation

The legacy implementation provides a single `PyroVelocity` class that handles all aspects of the model:

```python
import anndata as ad
import numpy as np
from pyrovelocity.models import PyroVelocity

# Load data
adata = ad.read_h5ad("path/to/data.h5ad")

# Set up AnnData for PyroVelocity
PyroVelocity.setup_anndata(adata)

# Create model
model = PyroVelocity(
    adata,
    model_type="normal",  # Options: "normal", "deterministic", "stochastic"
    guide_type="auto",    # Options: "auto", "delta"
    likelihood="Poisson", # Options: "Poisson", "NegativeBinomial"
    shared_time=True,     # Whether to use shared time across genes
    t_scale_on=False      # Whether to use time scaling
)

# Train model
model.train(
    max_epochs=1000,
    learning_rate=0.01,
    use_gpu="auto"
)

# Generate posterior samples
posterior_samples = model.generate_posterior_samples(
    adata=adata,
    num_samples=100
)

# Compute statistics from posterior samples
model.compute_statistics_from_posterior_samples(
    adata=adata,
    posterior_samples=posterior_samples
)

# Save model
model.save_model("path/to/save/model")

# Load model
model = PyroVelocity.load_model("path/to/save/model", adata)
```

## Modular Implementation

The modular implementation provides a more flexible approach with composable components:

```python
import anndata as ad
import numpy as np
from pyrovelocity.models.modular import (
    create_standard_model,
    PyroVelocityModel
)

# Load data
adata = ad.read_h5ad("path/to/data.h5ad")

# Set up AnnData for PyroVelocity
adata = PyroVelocityModel.setup_anndata(adata)

# Create model using factory function
model = create_standard_model()

# Train model
model.train(
    adata=adata,
    max_epochs=1000,
    learning_rate=0.01,
    use_gpu=False  # Set to True if GPU is available
)

# Generate posterior samples
posterior_samples = model.generate_posterior_samples(
    adata=adata,
    num_samples=100
)

# Store results in AnnData
adata = model.store_results_in_anndata(
    adata=adata,
    posterior_samples=posterior_samples
)
```

### Creating Custom Models

The modular implementation allows you to create custom models by combining different components:

```python
from pyrovelocity.models.modular.components import (
    StandardDynamicsModel,
    LogNormalPriorModel,
    PoissonLikelihoodModel,
    StandardObservationModel,
    AutoGuideFactory
)
from pyrovelocity.models.modular.model import PyroVelocityModel

# Create components
dynamics_model = StandardDynamicsModel(shared_time=True, t_scale_on=False)
prior_model = LogNormalPriorModel()
likelihood_model = PoissonLikelihoodModel()
observation_model = StandardObservationModel(correct_library_size=True)
guide_model = AutoGuideFactory()

# Create model
custom_model = PyroVelocityModel(
    dynamics_model=dynamics_model,
    prior_model=prior_model,
    likelihood_model=likelihood_model,
    observation_model=observation_model,
    guide_model=guide_model
)

# Train the model
custom_model.train(
    adata=adata,
    max_epochs=1000,
    learning_rate=0.01,
    use_gpu=False
)
```

### Using Factory Functions

The modular implementation provides factory functions for creating models with different configurations:

```python
from pyrovelocity.models.modular.factory import (
    create_standard_model,
    create_model_from_config,
    create_legacy_model1,
    create_legacy_model2
)
from pyrovelocity.models.modular.config import ModelConfig

# Create a standard model
standard_model = create_standard_model()

# Create a model that replicates the legacy implementation
legacy_model = create_legacy_model1()

# Create a model from a configuration
config = ModelConfig.standard()
config_model = create_model_from_config(config)
```

## Inference Parameters

Both implementations support the following inference parameters:

| Parameter | Description | Default |
|-----------|-------------|---------|
| max_epochs | Maximum number of training epochs | 1000 |
| learning_rate | Learning rate for the optimizer | 0.01 |
| batch_size | Batch size for mini-batch training | None (full dataset) |
| train_size | Fraction of data to use for training | 0.8 |
| valid_size | Fraction of data to use for validation | 0.2 |
| early_stopping | Whether to use early stopping | True |
| early_stopping_patience | Number of epochs to wait for improvement | 10 |
| use_gpu | Whether to use GPU for training | "auto" |

## Posterior Sampling

After training, you can generate posterior samples to quantify uncertainty:

```python
# Generate posterior samples
posterior_samples = model.generate_posterior_samples(
    adata=adata,
    num_samples=100
)
```

The posterior samples contain the following keys:

| Key | Description |
|-----|-------------|
| alpha | Transcription rate |
| beta | Splicing rate |
| gamma | Degradation rate |
| u_inf | Steady-state unspliced RNA |
| s_inf | Steady-state spliced RNA |
| t | Latent time |
| switching | Switching time |
| ut | Latent unspliced RNA |
| st | Latent spliced RNA |

## Conclusion

This guide covered the basics of inference with PyroVelocity, including both the legacy and modular implementations. For more advanced usage, refer to the [API reference](../reference/models.PyroVelocityModel.qmd) and the [modular components guide](model_components.qmd).